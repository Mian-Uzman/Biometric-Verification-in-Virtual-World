{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3613jvsc74a57bd0faaf9a5ea4b84c04376ea8354745a5d566b54cee8bf46ae02f76ce7364597cf2",
      "display_name": "Python 3.6.13 64-bit ('mlproj': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.13"
    },
    "metadata": {
      "interpreter": {
        "hash": "faaf9a5ea4b84c04376ea8354745a5d566b54cee8bf46ae02f76ce7364597cf2"
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCjPELjGwLTa"
      },
      "source": [
        "\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from keras.applications.vgg16 import VGG16\n",
        "import cv2\n",
        "import math\n",
        "import os\n",
        "from glob import glob\n",
        "from scipy import stats as s"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYYjdGw2zQFC"
      },
      "source": [
        "base_model = VGG16(weights='imagenet', include_top=False)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = load_model('final_model.model/')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2giTm49zwcPk"
      },
      "source": [
        "# getting the test list\n",
        "f = open(\"video-output/testlist.txt\", \"r\")\n",
        "temp = f.read()\n",
        "videos = temp.split('\\n')\n",
        "\n",
        "# creating the dataframe\n",
        "test = pd.DataFrame()\n",
        "test['video_name'] = videos\n",
        "test_videos = test['video_name']\n",
        "test.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           video_name\n",
              "0  pose-testing-1.mp4\n",
              "1  pose-testing-2.mp4\n",
              "2  pose-testing-3.mp4"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>video_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>pose-testing-1.mp4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>pose-testing-2.mp4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>pose-testing-3.mp4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSUAG1GdweuW"
      },
      "source": [
        "# creating the tags\n",
        "train = pd.read_csv('train_new.csv')\n",
        "y = train['class']\n",
        "y = pd.get_dummies(y)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4OXR58IwhDl"
      },
      "source": [
        "# creating two lists to store predicted and actual tags\n",
        "predict = []\n",
        "actual = []\n",
        "\n",
        "# for loop to extract frames from each test video\n",
        "for i in tqdm(range(test_videos.shape[0])):\n",
        "    count = 0\n",
        "    videoFile = test_videos[i]\n",
        "    cap = cv2.VideoCapture('video-output/'+videoFile)   # capturing the video from the given path\n",
        "    frameRate = cap.get(5) #frame rate\n",
        "    x=1\n",
        "    # removing all other files from the temp folder\n",
        "    files = glob('temp/*')\n",
        "    for f in files:\n",
        "        os.remove(f)\n",
        "    while(cap.isOpened()):\n",
        "        frameId = cap.get(1) #current frame number\n",
        "        ret, frame = cap.read()\n",
        "        if (ret != True):\n",
        "            break\n",
        "        if (frameId % math.floor(frameRate/4) == 0):\n",
        "            # storing the frames of this particular video in temp folder\n",
        "            filename ='temp/' + \"_frame%d.jpg\" % count;count+=1\n",
        "            cv2.imwrite(filename, frame)\n",
        "    cap.release()\n",
        "    \n",
        "    # reading all the frames from temp folder\n",
        "    images = glob(\"temp/*.jpg\")\n",
        "    \n",
        "    prediction_images = []\n",
        "    for i in range(len(images)):\n",
        "        img = image.load_img(images[i], target_size=(224,224,3))\n",
        "        img = image.img_to_array(img)\n",
        "        img = img/255\n",
        "        prediction_images.append(img)\n",
        "        \n",
        "    # converting all the frames for a test video into numpy array\n",
        "    prediction_images = np.array(prediction_images)\n",
        "    # extracting features using pre-trained model\n",
        "    prediction_images = base_model.predict(prediction_images)\n",
        "    # converting features in one dimensional array\n",
        "    prediction_images = prediction_images.reshape(prediction_images.shape[0], 7*7*512)\n",
        "    # predicting tags for each array\n",
        "    prediction = model.predict_classes(prediction_images)\n",
        "    # appending the mode of predictions in predict list to assign the tag to the video\n",
        "    predict.append(y.columns.values[s.mode(prediction)[0][0]])\n",
        "    # appending the actual tag of the video\n",
        "    actual.append(videoFile)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/3 [00:00<?, ?it/s]C:\\Users\\Mian Uzman\\anaconda3\\envs\\mlproj\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
            "100%|██████████| 3/3 [03:39<00:00, 73.22s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['p1', 'p2', 'p2']\n['pose-testing-1.mp4', 'pose-testing-2.mp4', 'pose-testing-3.mp4']\n"
          ]
        }
      ],
      "source": [
        "print(predict)\n",
        "print(actual)"
      ]
    }
  ]
}