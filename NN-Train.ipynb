{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3613jvsc74a57bd0faaf9a5ea4b84c04376ea8354745a5d566b54cee8bf46ae02f76ce7364597cf2",
      "display_name": "Python 3.6.13 64-bit ('mlproj': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.13"
    },
    "metadata": {
      "interpreter": {
        "hash": "faaf9a5ea4b84c04376ea8354745a5d566b54cee8bf46ae02f76ce7364597cf2"
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcwSD974M4BO"
      },
      "source": [
        "import cv2     # for capturing videos\n",
        "import math   # for mathematical operations\n",
        "import matplotlib.pyplot as plt    # for plotting the images\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "from keras.preprocessing import image   # for preprocessing the images\n",
        "import numpy as np    # for mathematical operations\n",
        "from keras.utils import np_utils\n",
        "from skimage.transform import resize   # for resizing images\n",
        "from sklearn.model_selection import train_test_split\n",
        "from glob import glob\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "um-9REmcsxjR",
        "outputId": "9c7a62ed-6061-402c-b57a-39ef328011cf"
      },
      "source": [
        "# open the .txt file which have names of training videos\n",
        "f = open(\"video-output/videolist.txt\", \"r\")\n",
        "temp = f.read()\n",
        "videos = temp.split('\\n')\n",
        "\n",
        "# creating a dataframe having video names\n",
        "train = pd.DataFrame()\n",
        "train['video_name'] = videos\n",
        "train.head()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      video_name\n",
              "0  pose-p1-1.mp4\n",
              "1  pose-p1-2.mp4\n",
              "2  pose-p1-3.mp4\n",
              "3  pose-p1-4.mp4\n",
              "4  pose-p1-5.mp4"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>video_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>pose-p1-1.mp4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>pose-p1-2.mp4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>pose-p1-3.mp4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>pose-p1-4.mp4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>pose-p1-5.mp4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "ZTBGk7-Qs2Nz",
        "outputId": "c58276e0-ebcc-4ff6-da49-f73a3dfd5e99"
      },
      "source": [
        "# open the .txt file which have names of test videos\n",
        "f = open(\"video-output/testlist.txt\", \"r\")\n",
        "temp = f.read()\n",
        "videos = temp.split('\\n')\n",
        "\n",
        "\n",
        "# creating a dataframe having video names\n",
        "test = pd.DataFrame()\n",
        "test['video_name'] = videos\n",
        "test.head()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           video_name\n",
              "0  pose-testing-1.mp4\n",
              "1  pose-testing-2.mp4\n",
              "2  pose-testing-3.mp4"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>video_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>pose-testing-1.mp4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>pose-testing-2.mp4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>pose-testing-3.mp4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLitygqHs9G5"
      },
      "source": [
        "# creating tags for training videos\n",
        "train_video_tag = []\n",
        "for i in range(train.shape[0]):\n",
        "    train_video_tag.append(train['video_name'][i].split('.')[0])\n",
        "    \n",
        "train['tag'] = train_video_tag\n",
        "\n",
        "# creating tags for test videos\n",
        "test_video_tag = []\n",
        "for i in range(test.shape[0]):\n",
        "    test_video_tag.append(test['video_name'][i].split('.')[0])\n",
        "    \n",
        "test['tag'] = test_video_tag"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfAarOINtA8A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78c1ce5b-e09d-4f40-86b3-22955718dc5a"
      },
      "source": [
        "# storing the frames from training videos\n",
        "for i in tqdm(range(train.shape[0])):    \n",
        "    count = 0\n",
        "    videoFile = train['video_name'][i]\n",
        "    cap = cv2.VideoCapture('video-output/'+videoFile)   # capturing the video from the given path\n",
        "    frameRate = cap.get(5) #frame rate\n",
        "    x=1\n",
        "    while(cap.isOpened()):\n",
        "        frameId = cap.get(1) #current frame number\n",
        "        ret, frame = cap.read()\n",
        "        if (ret != True):\n",
        "            break\n",
        "        if (frameId % math.floor(frameRate/4) == 0):\n",
        "            # storing the frames in a new folder named train_1\n",
        "            filename ='train_1/' + videoFile+f\"_frame{count}.jpg\"\n",
        "            count+=1\n",
        "            cv2.imwrite(filename, frame)\n",
        "    cap.release()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:47<00:00,  4.78s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX5texL2tE0C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0693aeec-b76e-48f0-9cc6-504b583c8db1"
      },
      "source": [
        "# getting the names of all the images\n",
        "images = glob(\"train_1/*.jpg\")\n",
        "train_image = []\n",
        "train_class = []\n",
        "for i in tqdm(range(len(images))):\n",
        "    # creating the image name\n",
        "    train_image.append(images[i])\n",
        "    # creating the class of image\n",
        "    train_class.append(images[i].split('_')[1].split(\"\\\\\")[1].split('-')[1])\n",
        "    \n",
        "# storing the images and their class in a dataframe\n",
        "train_data = pd.DataFrame()\n",
        "train_data['image'] = train_image\n",
        "train_data['class'] = train_class\n",
        "\n",
        "# converting the dataframe into csv file \n",
        "train_data.to_csv('train_new.csv',header=True, index=False)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9101/9101 [00:00<00:00, 758486.71it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# After preprocessing the Data we move on to training our model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82YnwA7PtHRT"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC7UgnpJtMh3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "c59be9b5-621c-46fd-d273-54ef0a3da83d"
      },
      "source": [
        "train = pd.read_csv('train_new.csv')\n",
        "train.head()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                image class\n",
              "0    train_1\\pose-p1-1.mp4_frame0.jpg    p1\n",
              "1    train_1\\pose-p1-1.mp4_frame1.jpg    p1\n",
              "2   train_1\\pose-p1-1.mp4_frame10.jpg    p1\n",
              "3  train_1\\pose-p1-1.mp4_frame100.jpg    p1\n",
              "4  train_1\\pose-p1-1.mp4_frame101.jpg    p1"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_1\\pose-p1-1.mp4_frame0.jpg</td>\n      <td>p1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_1\\pose-p1-1.mp4_frame1.jpg</td>\n      <td>p1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_1\\pose-p1-1.mp4_frame10.jpg</td>\n      <td>p1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_1\\pose-p1-1.mp4_frame100.jpg</td>\n      <td>p1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_1\\pose-p1-1.mp4_frame101.jpg</td>\n      <td>p1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vN3GPfv0tP9i",
        "outputId": "59b3e60f-c60a-40fb-acbd-97ff852081a6"
      },
      "source": [
        "# creating an empty list\n",
        "train_image = []\n",
        "\n",
        "# for loop to read and store frames\n",
        "for i in tqdm(range(train.shape[0])):\n",
        "    # loading the image and keeping the target size as (224,224,3)\n",
        "    img = image.load_img(train['image'][i], target_size=(224,224,3))\n",
        "    # converting it to array\n",
        "    img = image.img_to_array(img)\n",
        "    # normalizing the pixel value\n",
        "    img = img/255\n",
        "    # appending the image to the train_image list\n",
        "    train_image.append(img)\n",
        "    \n",
        "# converting the list to numpy array\n",
        "X = np.array(train_image)\n",
        "\n",
        "# shape of the array\n",
        "X.shape"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9101/9101 [02:06<00:00, 71.74it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9101, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mzp90IVVtTMq"
      },
      "source": [
        "# separating the target\n",
        "y = train['class']\n",
        "\n",
        "# creating the training and validation set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify = y)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zlJx2g9tYus"
      },
      "source": [
        "# creating dummies of target variable for train and validation set\n",
        "y_train = pd.get_dummies(y_train)\n",
        "y_test = pd.get_dummies(y_test)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLoy1zxqtbKx"
      },
      "source": [
        "# creating the base model of pre-trained VGG16 model\n",
        "base_model = VGG16(weights='imagenet', include_top=False)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5AUZ4yUt9oA"
      },
      "source": [
        "# extracting features for training frames\n",
        "X_train = base_model.predict(X_train)\n",
        "X_train.shape"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7280, 7, 7, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7bcmZ9FuDRL"
      },
      "source": [
        "# extracting features for validation frames\n",
        "X_test = base_model.predict(X_test)\n",
        "X_test.shape"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1821, 7, 7, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPbjYZcZuGYt"
      },
      "source": [
        "# reshaping the training as well as validation frames in single dimension\n",
        "X_train = X_train.reshape(7280,7*7*512)\n",
        "X_test = X_test.reshape(1821,7*7*512)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzMuI0NGuJyK"
      },
      "source": [
        "# normalizing the pixel values\n",
        "max = X_train.max()\n",
        "X_train = X_train/max\n",
        "X_test = X_test/max"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIO3ybt8uPOg"
      },
      "source": [
        "#defining the model architecture\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, activation='relu', input_shape=(25088,)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax'))"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQzvvsq5v3Le"
      },
      "source": [
        "# defining a function to save the weights of best model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "mcp_save = ModelCheckpoint('weight.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compiling the model\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLj--Jkrv9sO",
        "tags": []
      },
      "source": [
        "# training the model\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), callbacks=[mcp_save], batch_size=128)\n"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "57/57 [==============================] - 7s 113ms/step - loss: 7.3698e-04 - accuracy: 0.9997 - val_loss: 0.0019 - val_accuracy: 0.9989\n",
            "Epoch 2/10\n",
            "57/57 [==============================] - 6s 106ms/step - loss: 9.3527e-04 - accuracy: 0.9995 - val_loss: 0.0016 - val_accuracy: 0.9989\n",
            "Epoch 3/10\n",
            "57/57 [==============================] - 6s 106ms/step - loss: 0.0083 - accuracy: 0.9988 - val_loss: 0.0017 - val_accuracy: 0.9989\n",
            "Epoch 4/10\n",
            "57/57 [==============================] - 6s 107ms/step - loss: 0.0209 - accuracy: 0.9978 - val_loss: 0.0083 - val_accuracy: 0.9978\n",
            "Epoch 5/10\n",
            "57/57 [==============================] - 6s 105ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0055 - val_accuracy: 0.9984\n",
            "Epoch 6/10\n",
            "57/57 [==============================] - 6s 105ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.0014 - val_accuracy: 0.9989\n",
            "Epoch 7/10\n",
            "57/57 [==============================] - 6s 106ms/step - loss: 0.0016 - accuracy: 0.9989 - val_loss: 0.0015 - val_accuracy: 0.9989\n",
            "Epoch 8/10\n",
            "57/57 [==============================] - 6s 105ms/step - loss: 5.5257e-04 - accuracy: 0.9997 - val_loss: 0.0012 - val_accuracy: 0.9989\n",
            "Epoch 9/10\n",
            "57/57 [==============================] - 6s 106ms/step - loss: 4.5372e-04 - accuracy: 0.9998 - val_loss: 0.0019 - val_accuracy: 0.9989\n",
            "Epoch 10/10\n",
            "57/57 [==============================] - 6s 105ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0011 - val_accuracy: 0.9989\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1e60728b0f0>"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: final_model.model\\assets\n"
          ]
        }
      ],
      "source": [
        "model.save('final_model.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 67ms/step - loss: 0.0011 - accuracy: 0.9989\n",
            "Loss: 0.0011362413642928004\n",
            "Accuracy: 99.89017248153687\n"
          ]
        }
      ],
      "source": [
        "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size = 128)\n",
        "print(f\"Loss: {val_loss}\")\n",
        "print(f\"Accuracy: {val_acc * 100}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}